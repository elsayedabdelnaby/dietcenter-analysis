{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed26d362",
   "metadata": {},
   "source": [
    "# Program Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d66fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5865 entries, 0 to 5864\n",
      "Data columns (total 48 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   id_program                       5865 non-null   int64  \n",
      " 1   customer_id                      5865 non-null   int64  \n",
      " 2   program_id                       5865 non-null   int64  \n",
      " 3   promocode_id                     5864 non-null   float64\n",
      " 4   paid                             5865 non-null   int64  \n",
      " 5   paid_amount                      5865 non-null   float64\n",
      " 6   delivery_start_date              5865 non-null   object \n",
      " 7   total_days                       5865 non-null   int64  \n",
      " 8   free_days                        5865 non-null   int64  \n",
      " 9   status                           5865 non-null   object \n",
      " 10  created_at_program               5865 non-null   object \n",
      " 11  diet_program_name                5865 non-null   object \n",
      " 12  master_plan_name                 5781 non-null   object \n",
      " 13  subscribe_year                   5865 non-null   int64  \n",
      " 14  subscribe_month                  5865 non-null   int64  \n",
      " 15  subscribe_day                    5865 non-null   int64  \n",
      " 16  subscribe_weekday                5865 non-null   object \n",
      " 17  subscribe_quarter                5865 non-null   int64  \n",
      " 18  subscribe_month_name             5865 non-null   object \n",
      " 19  created_month_year_str_program   5865 non-null   object \n",
      " 20  created_month_year               5865 non-null   object \n",
      " 21  delivery_duration_days           5865 non-null   int64  \n",
      " 22  id_customer                      5865 non-null   int64  \n",
      " 23  username                         5865 non-null   object \n",
      " 24  email                            3075 non-null   object \n",
      " 25  nationality                      5865 non-null   object \n",
      " 26  gender                           5865 non-null   object \n",
      " 27  date_of_birth                    5865 non-null   object \n",
      " 28  age                              5865 non-null   float64\n",
      " 29  height                           5865 non-null   float64\n",
      " 30  weight                           5865 non-null   float64\n",
      " 31  created_at_customer              5863 non-null   object \n",
      " 32  deleted_at                       0 non-null      float64\n",
      " 33  birth_year                       5865 non-null   int64  \n",
      " 34  birth_month                      5865 non-null   int64  \n",
      " 35  birth_day                        5865 non-null   int64  \n",
      " 36  birth_weekday                    5865 non-null   object \n",
      " 37  birth_quarter                    5865 non-null   int64  \n",
      " 38  created_year                     5863 non-null   float64\n",
      " 39  created_month                    5863 non-null   float64\n",
      " 40  created_month_name               5863 non-null   object \n",
      " 41  created_day                      5863 non-null   float64\n",
      " 42  created_weekday                  5863 non-null   object \n",
      " 43  created_quarter                  5863 non-null   float64\n",
      " 44  email_domain                     3062 non-null   object \n",
      " 45  gender_encoded                   5865 non-null   int64  \n",
      " 46  bmi                              5865 non-null   float64\n",
      " 47  created_month_year_str_customer  5863 non-null   object \n",
      "dtypes: float64(11), int64(17), object(20)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('https://drive.google.com/file/d/1vqxpwQTbh80GILVhrm-id6efxcXjn3mu/view?usp=drive_link')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584f333",
   "metadata": {},
   "source": [
    "## 2. Target Variable Identification and Feature Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a26bf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable identified: program_id\n",
      "Shape of features (X): (5865, 45)\n",
      "Shape of target (y): (5865,)\n",
      "Number of unique programs: 196\n"
     ]
    }
   ],
   "source": [
    "# Define target variable\n",
    "target = \"program_id\"\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "# Exclude diet_program_name and master_plan_name to avoid data leakage\n",
    "X = df.drop(columns=[target, 'diet_program_name', 'master_plan_name'])\n",
    "y = df[target]\n",
    "\n",
    "print(f\"Target variable identified: {target}\")\n",
    "print(f\"Shape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (y): {y.shape}\")\n",
    "print(f\"Number of unique programs: {y.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106a47a",
   "metadata": {},
   "source": [
    "## 3. Feature Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9bd09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['paid', 'total_days', 'free_days', 'subscribe_year', 'subscribe_month', 'subscribe_day', 'subscribe_quarter', 'delivery_duration_days', 'id_customer', 'age', 'height', 'weight', 'birth_year', 'birth_month', 'birth_day', 'birth_quarter', 'created_year', 'created_month', 'created_day', 'created_quarter', 'gender_encoded', 'bmi']\n",
      "Categorical Features: ['status', 'subscribe_weekday', 'username', 'email', 'nationality', 'gender', 'birth_weekday', 'created_month_name', 'created_weekday', 'email_domain']\n"
     ]
    }
   ],
   "source": [
    "# Columns to exclude from automatic type inference for features\n",
    "exclude_cols = [target, 'id_program', 'customer_id', 'promocode_id', 'paid_amount',\n",
    "                'created_at_program', 'delivery_start_date', 'created_at_customer', 'date_of_birth',\n",
    "                'deleted_at', 'created_month_year_str_program', 'created_month_year_str_customer',\n",
    "                'subscribe_month_name', 'created_month_year']\n",
    "\n",
    "# Identify numerical features\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_features = [col for col in numerical_features if col not in exclude_cols]\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "categorical_features = [col for col in categorical_features if col not in exclude_cols]\n",
    "\n",
    "print(\"Numerical Features:\", numerical_features)\n",
    "print(\"Categorical Features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40582b1c",
   "metadata": {},
   "source": [
    "## 4. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fce0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4692, 45)\n",
      "Shape of X_test: (1173, 45)\n",
      "Shape of y_train: (4692,)\n",
      "Shape of y_test: (1173,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101bc1b",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36efbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created and applied.\n",
      "Shape of processed X_train: (4692, 4240)\n",
      "Shape of processed X_test: (1173, 4240)\n"
     ]
    }
   ],
   "source": [
    "# Numerical pipeline: Imputation + Scaling\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline: Imputation + One-Hot Encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Save the preprocessor for future use\n",
    "joblib.dump(preprocessor, \"program_preprocessor.pkl\")\n",
    "\n",
    "print(\"Preprocessing pipeline created and applied.\")\n",
    "print(f\"Shape of processed X_train: {X_train_processed.shape}\")\n",
    "print(f\"Shape of processed X_test: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764fb24",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c09330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier - Accuracy: 0.4561\n",
      "RandomForestClassifier - Classification Report:              precision    recall  f1-score   support\n",
      "\n",
      "  5637163328       0.57      0.67      0.62         6\n",
      "  5637163329       0.80      0.44      0.57         9\n",
      "  5637167076       1.00      0.11      0.20         9\n",
      "  5637167077       0.44      0.71      0.54        48\n",
      "  5637167078       0.67      0.33      0.44         6\n",
      "  5637167079       0.29      0.25      0.27         8\n",
      "  5637167080       0.42      0.70      0.52        63\n",
      "  5637167081       0.50      0.20      0.29         5\n",
      "  5637167082       0.38      0.40      0.39        15\n",
      "  5637167083       0.33      0.14      0.20         7\n",
      "  5637167084       0.41      0.39      0.40        18\n",
      "  5637167099       0.00      0.00      0.00         1\n",
      "  5637167101       0.59      0.40      0.48        40\n",
      "  5637167826       0.00      0.00      0.00         1\n",
      "  5637167828       0.00      0.00      0.00         1\n",
      "  5637167831       0.33      0.20      0.25         5\n",
      "  5637167832       0.00      0.00      0.00         2\n",
      "  5637167833       0.00      0.00      0.00         1\n",
      "  5637167834       0.00      0.00      0.00         1\n",
      "  5637167835       0.00      0.00      0.00         1\n",
      "  5637169326       0.00      0.00      0.00         1\n",
      "  5637169327       0.50      0.17      0.25         6\n",
      "  5637169328       1.00      0.50      0.67         2\n",
      "  5637169329       0.42      0.19      0.26        26\n",
      "  5637169330       0.55      0.32      0.40        19\n",
      "  5637169331       1.00      0.17      0.29         6\n",
      "  5637169332       0.20      0.25      0.22         4\n",
      "  5637169333       0.43      0.72      0.54        29\n",
      "  5637169334       0.00      0.00      0.00         1\n",
      "  5637169341       0.00      0.00      0.00         3\n",
      "  5637170078       0.00      0.00      0.00         1\n",
      "  5637170081       0.00      0.00      0.00         1\n",
      "  5637170082       0.00      0.00      0.00         0\n",
      "  5637170833       0.33      0.56      0.42         9\n",
      "  5637170834       0.50      0.54      0.52        24\n",
      "  5637170844       1.00      0.20      0.33         5\n",
      "  5637170854       0.00      0.00      0.00         1\n",
      "  5637170859       0.67      0.67      0.67         3\n",
      "  5637170860       0.00      0.00      0.00         2\n",
      "  5637170862       0.25      0.14      0.18         7\n",
      "  5637170863       0.00      0.00      0.00         1\n",
      "  5637170864       0.00      0.00      0.00         1\n",
      "  5637170865       0.25      0.10      0.14        10\n",
      "  5637170866       0.00      0.00      0.00         1\n",
      "  5637170867       0.48      0.76      0.59        70\n",
      "  5637170869       0.48      0.66      0.56        94\n",
      "  5637170870       0.44      0.50      0.47        24\n",
      "  5637170871       0.50      0.29      0.36         7\n",
      "  5637170872       0.25      0.20      0.22         5\n",
      "  5637170874       0.29      0.40      0.33        10\n",
      "  5637170875       1.00      0.33      0.50         6\n",
      "  5637170877       0.00      0.00      0.00         1\n",
      "  5637170879       0.00      0.00      0.00         1\n",
      "  5637170884       0.00      0.00      0.00         1\n",
      "  5637170885       0.00      0.00      0.00         1\n",
      "  5637170887       0.00      0.00      0.00         1\n",
      "  5637170888       0.00      0.00      0.00         1\n",
      "  5637170889       0.00      0.00      0.00         0\n",
      "  5637170890       0.00      0.00      0.00         1\n",
      "  5637170893       0.00      0.00      0.00         2\n",
      "  5637170895       1.00      0.33      0.50         3\n",
      "  5637170896       0.00      0.00      0.00         2\n",
      "  5637170897       0.00      0.00      0.00         1\n",
      "  5637170898       0.00      0.00      0.00         1\n",
      "  5637170899       0.00      0.00      0.00         0\n",
      "  5637170905       0.00      0.00      0.00         0\n",
      "  5637170909       0.00      0.00      0.00         1\n",
      "  5637170911       0.00      0.00      0.00         1\n",
      "  5637171577       0.50      0.40      0.44        10\n",
      "  5637171578       0.60      0.43      0.50         7\n",
      "  5637172392       0.75      0.43      0.55         7\n",
      "  5637172393       0.33      0.33      0.33         6\n",
      "  5637172394       0.00      0.00      0.00         3\n",
      "  5637172399       1.00      1.00      1.00         1\n",
      "  5637172400       0.00      0.00      0.00         4\n",
      "  5637172401       0.00      0.00      0.00         2\n",
      "  5637172405       0.00      0.00      0.00         1\n",
      "  5637173077       0.00      0.00      0.00         2\n",
      "  5637173078       0.00      0.00      0.00         1\n",
      "  5637173080       1.00      1.00      1.00         1\n",
      "  5637173082       0.50      0.14      0.22         7\n",
      "  5637173083       0.00      0.00      0.00         4\n",
      "  5637173084       0.00      0.00      0.00         0\n",
      "  5637173087       0.00      0.00      0.00         1\n",
      "  5637173088       1.00      1.00      1.00         4\n",
      "  5637173091       0.75      1.00      0.86         3\n",
      "  5637173092       0.00      0.00      0.00         1\n",
      "  5637173826       0.00      0.00      0.00         1\n",
      "  5637173827       0.75      0.60      0.67         5\n",
      "  5637173830       0.36      0.23      0.28        35\n",
      "  5637173831       0.75      0.86      0.80         7\n",
      "  5637174588       1.00      0.50      0.67         2\n",
      "  5637174589       0.50      0.67      0.57         3\n",
      "  5637174590       0.00      0.00      0.00         1\n",
      "  5637174591       0.00      0.00      0.00         1\n",
      "  5637175343       0.00      0.00      0.00         1\n",
      "  5637176826       0.00      0.00      0.00         3\n",
      "  5637176828       0.00      0.00      0.00         3\n",
      "  5637176829       0.00      0.00      0.00         2\n",
      "  5637176830       0.00      0.00      0.00         1\n",
      "  5637176834       0.00      0.00      0.00         1\n",
      "  5637176835       0.00      0.00      0.00         2\n",
      "  5637176848       0.50      0.17      0.25         6\n",
      "  5637176852       0.60      0.38      0.46         8\n",
      "  5637176859       0.42      0.36      0.38        14\n",
      "  5637176860       0.62      0.23      0.33        22\n",
      "  5637176869       0.00      0.00      0.00         1\n",
      "  5637176870       0.00      0.00      0.00         0\n",
      "  5637176917       0.00      0.00      0.00         1\n",
      "  5637176918       0.48      0.62      0.54        21\n",
      "  5637176919       0.00      0.00      0.00         2\n",
      "  5637176920       0.20      0.50      0.29         4\n",
      "  5637176922       0.00      0.00      0.00         1\n",
      "  5637176927       0.00      0.00      0.00         1\n",
      "  5637176930       0.00      0.00      0.00         1\n",
      "  5637176931       0.00      0.00      0.00         4\n",
      "  5637176932       0.00      0.00      0.00         2\n",
      "  5637176933       0.00      0.00      0.00         3\n",
      "  5637176937       0.00      0.00      0.00         1\n",
      "  5637176938       0.00      0.00      0.00         2\n",
      "  5637177578       0.60      0.51      0.55        49\n",
      "  5637177579       0.38      0.64      0.48        64\n",
      "  5637177580       0.60      0.43      0.50         7\n",
      "  5637177581       1.00      0.17      0.29         6\n",
      "  5637178326       0.57      0.29      0.38        14\n",
      "  5637178327       0.17      0.12      0.14        26\n",
      "  5637179079       0.00      0.00      0.00         0\n",
      "  5637179081       0.00      0.00      0.00         1\n",
      "  5637179082       1.00      0.50      0.67         2\n",
      "  5637179087       0.00      0.00      0.00         2\n",
      "  5637179090       0.50      0.33      0.40         3\n",
      "  5637179091       0.00      0.00      0.00         1\n",
      "  5637180576       0.00      0.00      0.00         5\n",
      "  5637180578       0.00      0.00      0.00         4\n",
      "  5637180579       1.00      1.00      1.00         1\n",
      "  5637180580       0.56      0.50      0.53        30\n",
      "  5637180581       0.60      0.84      0.70        56\n",
      "  5637180583       0.00      0.00      0.00         2\n",
      "  5637180589       0.00      0.00      0.00         0\n",
      "  5637180598       0.50      0.15      0.24        13\n",
      "  5637180599       0.00      0.00      0.00         5\n",
      "  5637180600       1.00      0.33      0.50         3\n",
      "  5637180601       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.46      1173\n",
      "   macro avg       0.28      0.21      0.22      1173\n",
      "weighted avg       0.45      0.46      0.42      1173\n",
      "\n",
      "RandomForestClassifier model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the RandomForestClassifier model\n",
    "# Using default parameters for now, can tune later if needed\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf, zero_division=0)\n",
    "\n",
    "print(f\"RandomForestClassifier - Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"RandomForestClassifier - Classification Report:{report_rf}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(rf_model, \"random_forest_classifier_program_model.pkl\")\n",
    "print(\"RandomForestClassifier model trained and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2799932",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c074562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features:\n",
      "                                feature  importance\n",
      "1                            total_days    0.049536\n",
      "8                           id_customer    0.038713\n",
      "3                        subscribe_year    0.034658\n",
      "5                         subscribe_day    0.034514\n",
      "4                       subscribe_month    0.033005\n",
      "7                delivery_duration_days    0.029859\n",
      "21                                  bmi    0.024649\n",
      "11                               weight    0.024198\n",
      "12                           birth_year    0.023892\n",
      "18                          created_day    0.023867\n",
      "10                               height    0.023497\n",
      "9                                   age    0.023419\n",
      "14                            birth_day    0.023324\n",
      "13                          birth_month    0.021232\n",
      "16                         created_year    0.020999\n",
      "6                     subscribe_quarter    0.020607\n",
      "2                             free_days    0.016645\n",
      "15                        birth_quarter    0.016081\n",
      "17                        created_month    0.014905\n",
      "3278  email_eng.abdulaziz2010@gmail.com    0.009906\n"
     ]
    }
   ],
   "source": [
    "# Get feature names after preprocessing\n",
    "feature_names = []\n",
    "\n",
    "# Add numerical feature names\n",
    "feature_names.extend(numerical_features)\n",
    "\n",
    "# Add categorical feature names (after one-hot encoding)\n",
    "cat_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "feature_names.extend(cat_feature_names)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a dataframe for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 20 most important features\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08eefd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['program_name_mapping.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_mapping = df.set_index('program_id')['diet_program_name'].to_dict()\n",
    "\n",
    "# Save the mapping dictionary to a pickle file\n",
    "joblib.dump(program_mapping, 'program_name_mapping.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475feebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e54593",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
